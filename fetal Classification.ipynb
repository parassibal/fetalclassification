{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Building CNN-based model using Keras and Tensorflow and Fine-tuned Resnet with Pytorch that is capable of classifying anatomical structure in 2D fetal ultrasound images on AWS Sagemaker \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A zip file named \"Task1.zip\" is added to JuypterLab notebook in AWS Sagemaker. Form extraction, installing unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1Qo7lMQJ5pO"
   },
   "outputs": [],
   "source": [
    "# Unzipping Task1.zip\n",
    "!unzip Task1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now file structure \n",
    "#                              Classification\n",
    "#                              /     |      \\ \n",
    "#                           csv   image   test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuS-TDWZMz_O",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Our training images are in Classification/images. Now, getting all image files for this dir\n",
    "import os\n",
    "current_dir = \"Classification/images\"\n",
    "image_data = []\n",
    "for i in os.listdir(current_dir):\n",
    "    image_data.append(current_dir + \"/\" + i)\n",
    "len(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJ-0eFL1L6gb"
   },
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"image_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZYelzwfGM2H-",
    "outputId": "a5e7973a-4ea7-4650-edb6-ad2f22777ef4"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the train_data dataframe Image_name column with dir locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYSBNo_eM6WD"
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_data.Image_name)):\n",
    "    train_data.Image_name.iloc[i] = \"Classification/images/\" + str(train_data.Image_name.iloc[i]) + \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bQBpHnbtNZn7",
    "outputId": "20989250-938c-4f0b-e90d-b059cb16d999"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "usGp7TrXNbeE",
    "outputId": "e290f77f-5204-40b3-f1c1-13ee69316e13"
   },
   "outputs": [],
   "source": [
    "train_data.Image_name.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our testing images without label are in Classification/External Test images. Now, getting all image files for this dir\n",
    "import os\n",
    "current_dir = \"Classification/External Test images\"\n",
    "test_data = []\n",
    "for i in os.listdir(current_dir):\n",
    "    test_data.append(current_dir + \"/\" + i)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now checking if there is any file without an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIwTX02IQzOK"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "idx_train = []\n",
    "for i in range(len(train_data.Image_name)):\n",
    "    with Image.open(train_data.Image_name.iloc[i]) as img:\n",
    "      if img.verify():\n",
    "          print(\"Not an image encountered\")\n",
    "          idx_train.append(i)\n",
    "idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "idx_test = []\n",
    "for i in range(len(test_data)):\n",
    "    with Image.open(test_data[i]) as img:\n",
    "      if img.verify():\n",
    "          print(\"Not an image encountered\")\n",
    "          idx_test.append(i)\n",
    "idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the dataframe\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for any missing labels\n",
    "train_data['Plane'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu8ilO-WM8IW",
    "outputId": "323b93a0-79b4-4166-a3af-e0c776122cb6"
   },
   "outputs": [],
   "source": [
    "# Determining the types of unique classes\n",
    "classes = train_data.Plane.unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now Seperating the data images based on 4 different classes identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHzXyarDNjII"
   },
   "outputs": [],
   "source": [
    "classes_dict = {val: train_data[train_data['Plane'] == val]['Image_name'].tolist() for val in classes}\n",
    "f_brain = classes_dict[\"Fetal brain\"]\n",
    "f_femur = classes_dict[\"Fetal femur\"]\n",
    "f_thorax = classes_dict[\"Fetal thorax\"]\n",
    "f_abdomen = classes_dict[\"Fetal abdomen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xllaCQT_OuKT",
    "outputId": "e2ad8d44-c769-435f-f306-f1b12ab9b139"
   },
   "outputs": [],
   "source": [
    "# Making sure we have identified all the samples\n",
    "len(f_brain) + len(f_femur) + len(f_thorax) + len(f_abdomen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the distribution of images in terms of their size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8Ro607Lq9MU"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p44lq34dqlC_"
   },
   "outputs": [],
   "source": [
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for i in range(len(train_data.Image_name)):\n",
    "    img = cv2.imread(train_data.Image_name.iloc[i], cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = img.shape\n",
    "    widths.append(w)\n",
    "    heights.append(h)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist(widths, bins=20, color='blue', edgecolor='black')\n",
    "axes[0].set_title('Image Width Distribution')\n",
    "axes[0].set_xlabel('Width')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[1].hist(heights, bins=20, color='green', edgecolor='black')\n",
    "axes[1].set_title('Image Height Distribution')\n",
    "axes[1].set_xlabel('Height')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLLDgb8kPbZA",
    "outputId": "4802acb7-5f4f-4c82-cb75-8d5b5b3d4c12"
   },
   "source": [
    "# Now checking the unique classes distribution sizes and if there is any imbalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-TJQhHxsEkm",
    "outputId": "2fa951f6-67f1-4258-eb0d-ca249693fef8"
   },
   "outputs": [],
   "source": [
    "num_f_brain = len(f_brain)\n",
    "num_f_femur = len(f_femur)\n",
    "num_f_thorax = len(f_thorax)\n",
    "num_f_abdomen = len(f_abdomen)\n",
    "total_images = len(f_brain) + len(f_femur) + len(f_thorax) + len(f_abdomen)\n",
    "print(\"brain:\", num_f_brain)\n",
    "print(\"femur:\", num_f_femur)\n",
    "print(\"thorax:\", num_f_thorax)\n",
    "print(\"abdomen:\", num_f_abdomen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "DoMbTzx9sVqy",
    "outputId": "7a3d0b29-cea6-4b1e-b748-881d2d3c91d2"
   },
   "outputs": [],
   "source": [
    "classes = train_data.Plane.unique()\n",
    "counts = [num_f_brain, num_f_femur, num_f_thorax, num_f_abdomen]\n",
    "plt.bar(classes, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Images in Each Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ajy4bDaGtCcF"
   },
   "outputs": [],
   "source": [
    "def mask_analysis():\n",
    "    image_files = train_data.Image_name\n",
    "    images = [cv2.imread(img_f, cv2.IMREAD_GRAYSCALE) for img_f in image_files]\n",
    "    masks = []\n",
    "    for img in images:\n",
    "        mask = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        masks.append(mask)\n",
    "        mask[mask != 255] = 0\n",
    "    for i in range(3):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(masks[i], cmap='gray')\n",
    "        plt.title('Generated Mask')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Display masks of normal images\n",
    "mask_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now making all classes sample size equal to handle the imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique used - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_XkzErMVU1c"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "bHMDeFc8QjGD",
    "outputId": "c3ac06d3-3795-4a78-d0e9-8a678346496b"
   },
   "outputs": [],
   "source": [
    "target_num_samples = max(num_f_brain, num_f_femur, num_f_thorax, num_f_abdomen)\n",
    "oversampled_brain_image_paths = random.choices(f_brain, k = target_num_samples)\n",
    "oversampled_femur_image_paths = random.choices(f_femur, k = target_num_samples)\n",
    "oversampled_thorax_image_paths = random.choices(f_thorax, k = target_num_samples)\n",
    "oversampled_abdomen_image_paths = random.choices(f_abdomen, k = target_num_samples)\n",
    "num_f_brain = len(oversampled_brain_image_paths)\n",
    "num_f_femur = len(oversampled_femur_image_paths)\n",
    "num_f_thorax = len(oversampled_thorax_image_paths)\n",
    "num_f_abdomen = len(oversampled_abdomen_image_paths)\n",
    "\n",
    "print(\"Number of images for each class after Oversampling\")\n",
    "print(\"Brain:\", num_f_brain)\n",
    "print(\"Femur:\", num_f_femur)\n",
    "print(\"Thorax:\", num_f_thorax)\n",
    "print(\"Abdomen:\", num_f_abdomen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [num_f_brain, num_f_femur, num_f_thorax, num_f_abdomen]\n",
    "plt.bar(classes, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Images in Each Class after Oversampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now resizing images and normalizing to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3yNfkSFu5wH"
   },
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def resize_images(image_paths):\n",
    "    images = []\n",
    "    for filepath in image_paths:\n",
    "        img = Image.open(filepath)\n",
    "        img = np.array(img.resize(img_size))\n",
    "        img_array = np.array(img) / 255.0\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "processed_brain_images = resize_images(oversampled_brain_image_paths)\n",
    "processed_femur_images = resize_images(oversampled_femur_image_paths)\n",
    "processed_thorax_images = resize_images(oversampled_thorax_image_paths)\n",
    "processed_abdomen_images = resize_images(oversampled_abdomen_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now performing the Data Augmentation using ImageDataGenerator to improve generalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ygaoL2F32sr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator with augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5RKc7PD3p1J"
   },
   "outputs": [],
   "source": [
    "#function to perform augmentation\n",
    "def augment_images(images_array, num_augmented_per_image=10):\n",
    "    reshaped_images = images_array.reshape(images_array.shape[0], 224, 224, 1)\n",
    "    datagen.fit(reshaped_images)\n",
    "    augmented_images = []\n",
    "    for x_batch in datagen.flow(reshaped_images, batch_size=1):\n",
    "        augmented_images.extend(x_batch)\n",
    "        if len(augmented_images) >= len(reshaped_images) * num_augmented_per_image:\n",
    "            break\n",
    "    return np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling augmentation_image with augmentation_factor = 5\n",
    "augmented_brain_images = augment_images(processed_brain_images, num_augmented_per_image = 5)\n",
    "augmented_femur_images = augment_images(processed_femur_images, num_augmented_per_image = 5)\n",
    "augmented_thorax_images = augment_images(processed_thorax_images, num_augmented_per_image = 5)\n",
    "augmented_abdomen_images = augment_images(processed_abdomen_images, num_augmented_per_image = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now creating labels for classes as 0, 1, 2, 3\n",
    "# We can use label encoder for it. Since the number of classes are limited to 4, creating labels manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 0 , 1, 2, 3 -> brain, femur, thorax, abdomen\n",
    "brain_labels = np.zeros((len(augmented_brain_images),), dtype=int)\n",
    "femur_labels = np.ones((len(augmented_femur_images),), dtype=int)\n",
    "thorax_labels = np.full((len(augmented_thorax_images),), 2)\n",
    "abdomen_labels = np.full((len(augmented_abdomen_images),), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "vJdY7D1s3_4a",
    "outputId": "62f0d981-00da-4e70-892e-0fd9a3d9fb1b"
   },
   "outputs": [],
   "source": [
    "# Concatenate augmented images into a single\n",
    "X = np.concatenate([augmented_brain_images, augmented_femur_images, augmented_thorax_images, augmented_abdomen_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rETt_KyTYiTP"
   },
   "outputs": [],
   "source": [
    "if len(X.shape) == 3:\n",
    "    X = np.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate labels into a single\n",
    "y = np.concatenate([brain_labels, femur_labels, thorax_labels, abdomen_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWHndJvo4zTf"
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now preparing data for training by splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akS31xGw5cK5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHP-Qfd55Kwd"
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split the temporary data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builing and Training the model using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Simple CNN model - 7 layers\n",
    "\n",
    "# Conv2D Layers \n",
    "32 filters, each with 3x3 kernel\n",
    "64 filters, each with  3x3 kernel\n",
    "Activation function: ReLU\n",
    "Input shape: (224, 224, 1)\n",
    "\n",
    "# MaxPooling2D Layer\n",
    "2x2 pooling window\n",
    "\n",
    "#Flatten Layer\n",
    "Flatten the output to a 1D array\n",
    "\n",
    "#Dense Layer (Fully Connected)\n",
    "128 neurons (units/nodes)\n",
    "Activation function: ReLU\n",
    "\n",
    "#Dense Layer (Output Layer)\n",
    "4 neurons\n",
    "Activation function: Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "simple_model.compile(optimizer = Adam(learning_rate=0.001),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preventing overfitting by introducing early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model for 50 epochs\n",
    "simple_model_history = simple_model.fit(datagen.flow(X_train, y_train, batch_size = 64), epochs=50, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric obtained from training\n",
    "training_accuracy = simple_model_history.history['accuracy']\n",
    "training_loss = simple_model_history.history['loss']\n",
    "validation_accuracy = simple_model_history.history['val_accuracy']\n",
    "validation_loss = simple_model_history.history['val_loss']\n",
    "print(\"training accuracy is : \", training_accuracy)\n",
    "print(\"training loss is : \", training_loss)\n",
    "print(\"validation accuracy is : \", validation_accuracy)\n",
    "print(\"validation loss is : \", validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "test_loss, test_accuracy = simple_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = simple_model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_val, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building more complex CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model.compile(optimizer = Adam(learning_rate=0.001),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preventing overfitting by introducing early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model_history = complex_model.fit(datagen.flow(X_train, y_train, batch_size = 64), epochs = 50, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "test_loss, test_accuracy = complex_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Resnet with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomRotation, ColorJitter\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for training and determining the best values\n",
    "def train_model(model, lossFunction, optimizer, X_train, X_val, y_train, y_val, device, num_epochs=50, patience=2, batch_size=32):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')  \n",
    "    consecutive_epochs_without_improvement = 0\n",
    "\n",
    "    # Converting data to tensor\n",
    "    X_train = torch.tensor(X_train, dtype = torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype = torch.long).to(device)\n",
    "    X_val = torch.tensor(X_val, dtype = torch.float32).to(device)\n",
    "    y_val = torch.tensor(y_val, dtype = torch.long).to(device)\n",
    "\n",
    "    # Creating dataloaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "    dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "    dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # training mode\n",
    "            else:\n",
    "                model.eval()   # evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = lossFunction(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    consecutive_epochs_without_improvement = 0\n",
    "                else:\n",
    "                    consecutive_epochs_without_improvement += 1\n",
    "\n",
    "        if consecutive_epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping after {epoch} epochs\")\n",
    "            break\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:.4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # classification report and confusion matrix\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning Resnet101 and adding additional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet101 = models.resnet101(weights=True)\n",
    "Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning weighting by setting param.requires_grad = True \n",
    "for param in Resnet101.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get input features and, replacing last fully connected layer based on model\n",
    "in_features = Resnet101.fc.in_features\n",
    "Resnet101.fc = nn.Linear(in_features, len(classes))\n",
    "# adding additional layer\n",
    "Resnet101.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet_fineTuning = Resnet101.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimzation, learning rate, loss to be used\n",
    "optimizer = optim.Adam(Resnet_fineTuning.parameters(), lr = 0.00005)\n",
    "learning_rate = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "Loss_Function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_val_tensor = torch.from_numpy(X_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the tensors to [batch_size, channels, height, width]\n",
    "X_train_tensor = X_train_tensor.permute(0, 3, 1, 2)\n",
    "X_val_tensor = X_val_tensor.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = train_model(Resnet_fineTuning, Loss_Function, optimizer,  X_train_tensor, X_val_tensor, y_train, y_val, device, num_epochs = 1, patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tuned_model, \"Resnet_fineTuning.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the tensors to [batch_size, channels, height, width]\n",
    "X_test_tensor = X_test_tensor.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test_tensor, dtype = torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype = torch.long).to(device)\n",
    "\n",
    "# Creating test dataloaders\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "test_dataloader = {'test': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting data\n",
    "from torch.utils.data import DataLoader\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader['test']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = tuned_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_true, y_pred, target_names = classes, output_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
